{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-02T01:10:47.927559700Z",
     "start_time": "2026-01-02T01:10:45.258252600Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:10:50.108143400Z",
     "start_time": "2026-01-02T01:10:50.039916600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "# Emotion mapping\n",
    "EMO_MAP = {\n",
    "    \"ANG\": 0,\n",
    "    \"DIS\": 1,\n",
    "    \"FEA\": 2,\n",
    "    \"HAP\": 3,\n",
    "    \"NEU\": 4,\n",
    "    \"SAD\": 5\n",
    "}\n",
    "NUM_CLASSES = len(EMO_MAP)\n",
    "\n",
    "# Data location\n",
    "NPY_DIR = \"mel_npy\"\n"
   ],
   "id": "db1f64cf2948b449",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:10:52.369146900Z",
     "start_time": "2026-01-02T01:10:52.305821500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "npy_paths = sorted([str(p) for p in Path(NPY_DIR).glob(\"*.npy\")])\n",
    "print(\"Found NPY files:\", len(npy_paths))\n"
   ],
   "id": "1ca8b123f871d6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found NPY files: 7431\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:24.429676600Z",
     "start_time": "2026-01-02T01:13:24.383978100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example = np.load(npy_paths[0])\n",
    "if example.ndim == 3:\n",
    "    _, N_MELS, T_FRAMES = example.shape\n",
    "else:\n",
    "    N_MELS, T_FRAMES = example.shape\n",
    "\n",
    "print(\"Spectrogram shape:\", (1, N_MELS, T_FRAMES))\n"
   ],
   "id": "238815d25525f0b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrogram shape: (1, 128, 188)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:26.341498900Z",
     "start_time": "2026-01-02T01:13:26.330013200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_actor_and_emotion(filename: str):\n",
    "\n",
    "    # Actor ID = first number in filename\n",
    "    actor_match = re.search(r\"\\d+\", filename)\n",
    "    if actor_match is None:\n",
    "        raise ValueError(f\"No actor ID in {filename}\")\n",
    "    actor_id = actor_match.group(0)\n",
    "\n",
    "    # Emotion code\n",
    "    emotion = None\n",
    "    for emo in EMO_MAP:\n",
    "        if f\"_{emo}_\" in filename or filename.startswith(f\"{emo}_\"):\n",
    "            emotion = EMO_MAP[emo]\n",
    "            break\n",
    "\n",
    "    if emotion is None:\n",
    "        raise ValueError(f\"No emotion code in {filename}\")\n",
    "\n",
    "    return actor_id, emotion\n"
   ],
   "id": "c47cd7f760274f0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:27.957180300Z",
     "start_time": "2026-01-02T01:13:27.926342500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def actor_independent_split(paths, train_ratio=0.7, val_ratio=0.15):\n",
    "    by_actor = {}\n",
    "\n",
    "    for p in paths:\n",
    "        fname = os.path.basename(p)\n",
    "        actor_id, _ = parse_actor_and_emotion(fname)\n",
    "        by_actor.setdefault(actor_id, []).append(p)\n",
    "\n",
    "    actors = list(by_actor.keys())\n",
    "    random.shuffle(actors)\n",
    "\n",
    "    n = len(actors)\n",
    "    n_train = int(n * train_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "\n",
    "    train_actors = set(actors[:n_train])\n",
    "    val_actors   = set(actors[n_train:n_train+n_val])\n",
    "    test_actors  = set(actors[n_train+n_val:])\n",
    "\n",
    "    def collect(actor_set):\n",
    "        out = []\n",
    "        for a in actor_set:\n",
    "            out.extend(by_actor[a])\n",
    "        return out\n",
    "\n",
    "    return (\n",
    "        collect(train_actors),\n",
    "        collect(val_actors),\n",
    "        collect(test_actors)\n",
    "    )\n"
   ],
   "id": "d817b5db64da0e1b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:31.449556Z",
     "start_time": "2026-01-02T01:13:31.396462200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_paths, val_paths, test_paths = actor_independent_split(npy_paths)\n",
    "print(len(train_paths), len(val_paths), len(test_paths))\n"
   ],
   "id": "35dc645d43b3a770",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5149 1065 1217\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:34.822078200Z",
     "start_time": "2026-01-02T01:13:34.804618900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MelNPYDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        fname = os.path.basename(path)\n",
    "\n",
    "        # loading spectrogram\n",
    "        spec = np.load(path).astype(np.float32)\n",
    "        if spec.ndim == 2:\n",
    "            spec = spec[np.newaxis, :, :]\n",
    "\n",
    "        # parsing label from filename\n",
    "        _, label = parse_actor_and_emotion(fname)\n",
    "\n",
    "        x = torch.from_numpy(spec)\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "        return x, y\n"
   ],
   "id": "d21152d2b96ef118",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:36.717085200Z",
     "start_time": "2026-01-02T01:13:36.703069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    MelNPYDataset(train_paths),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    MelNPYDataset(val_paths),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    MelNPYDataset(test_paths),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n"
   ],
   "id": "d1e12a99ab4b5012",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:38.776921500Z",
     "start_time": "2026-01-02T01:13:38.727773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n"
   ],
   "id": "280adc569635e4f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:41.980228600Z",
     "start_time": "2026-01-02T01:13:41.960828100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNNBiLSTM(nn.Module):\n",
    "    def __init__(self, lstm_hidden=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1)),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,1))\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, N_MELS, T_FRAMES)\n",
    "            z = self.cnn(dummy)\n",
    "            C, Fp, Tp = z.shape[1], z.shape[2], z.shape[3]\n",
    "            lstm_in = C * Fp\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=lstm_in,\n",
    "            hidden_size=lstm_hidden,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2*lstm_hidden, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, NUM_CLASSES)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.cnn(x)                 # (B, C, F, T)\n",
    "        z = z.permute(0, 3, 1, 2)       # (B, T, C, F)\n",
    "        z = z.flatten(2)                # (B, T, C*F)\n",
    "        out, _ = self.lstm(z)           # (B, T, 2H)\n",
    "\n",
    "        # Better than out[:, -1] for emotion:\n",
    "        out = out.mean(dim=1)           # (B, 2H)\n",
    "\n",
    "        return self.fc(out)\n"
   ],
   "id": "2e1851569f24af95",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T01:13:46.436695200Z",
     "start_time": "2026-01-02T01:13:44.697839500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        y = y.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_true.append(y.numpy())\n",
    "\n",
    "    y_pred = np.concatenate(all_preds)\n",
    "    y_true = np.concatenate(all_true)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    return acc, macro_f1\n"
   ],
   "id": "a2c78d6da012f43c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T02:23:24.721229700Z",
     "start_time": "2026-01-02T01:13:51.862056100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = CNNBiLSTM(lstm_hidden=128).to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-3)\n",
    "\n",
    "# scheduler reduces LR when metric plateaus\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.5, patience=2, min_lr=1e-6\n",
    ")\n",
    "\n",
    "# training limits and early stopping settings\n",
    "# early stopping will be triggered if there are no improvements for 8 epochs\n",
    "max_epochs = 120\n",
    "early_patience = 8\n",
    "best_val = -1.0\n",
    "wait = 0\n",
    "best_path = \"best_cremad.pt\"\n",
    "\n",
    "for epoch in range(1, max_epochs + 1):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_acc, val_f1 = evaluate(model, val_loader)\n",
    "\n",
    "    target_metric = val_f1\n",
    "    scheduler.step(target_metric)\n",
    "\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    print(f\"Epoch {epoch:03d} | train_loss {train_loss:.4f} | val_acc {val_acc:.4f} | val_f1 {val_f1:.4f} | lr {lr:.2e}\")\n",
    "\n",
    "    if target_metric > best_val + 1e-4:\n",
    "        best_val = target_metric\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), best_path)\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= early_patience:\n",
    "            print(f\"Early stopping. Best val_f1={best_val:.4f}\")\n",
    "            break\n",
    "\n",
    "# loading best checkpoint\n",
    "model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "best_acc, best_f1 = evaluate(model, val_loader)\n",
    "print(f\"BEST CHECKPOINT | val_acc={best_acc:.4f} | val_macro_f1={best_f1:.4f}\")\n"
   ],
   "id": "4a872c554c6119e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss 1.5970 | val_acc 0.3587 | val_f1 0.3117 | lr 3.00e-04\n",
      "Epoch 002 | train_loss 1.4722 | val_acc 0.4291 | val_f1 0.3599 | lr 3.00e-04\n",
      "Epoch 003 | train_loss 1.4321 | val_acc 0.4451 | val_f1 0.4075 | lr 3.00e-04\n",
      "Epoch 004 | train_loss 1.3891 | val_acc 0.4451 | val_f1 0.4140 | lr 3.00e-04\n",
      "Epoch 005 | train_loss 1.3581 | val_acc 0.4638 | val_f1 0.4409 | lr 3.00e-04\n",
      "Epoch 006 | train_loss 1.3101 | val_acc 0.4911 | val_f1 0.4736 | lr 3.00e-04\n",
      "Epoch 007 | train_loss 1.2908 | val_acc 0.4995 | val_f1 0.4872 | lr 3.00e-04\n",
      "Epoch 008 | train_loss 1.2468 | val_acc 0.5127 | val_f1 0.5015 | lr 3.00e-04\n",
      "Epoch 009 | train_loss 1.2142 | val_acc 0.5099 | val_f1 0.5007 | lr 3.00e-04\n",
      "Epoch 010 | train_loss 1.1779 | val_acc 0.5099 | val_f1 0.5005 | lr 3.00e-04\n",
      "Epoch 011 | train_loss 1.1516 | val_acc 0.5446 | val_f1 0.5351 | lr 3.00e-04\n",
      "Epoch 012 | train_loss 1.1129 | val_acc 0.5221 | val_f1 0.5179 | lr 3.00e-04\n",
      "Epoch 013 | train_loss 1.0917 | val_acc 0.5587 | val_f1 0.5552 | lr 3.00e-04\n",
      "Epoch 014 | train_loss 1.0728 | val_acc 0.5577 | val_f1 0.5562 | lr 3.00e-04\n",
      "Epoch 015 | train_loss 1.0278 | val_acc 0.5653 | val_f1 0.5657 | lr 3.00e-04\n",
      "Epoch 016 | train_loss 1.0045 | val_acc 0.5756 | val_f1 0.5708 | lr 3.00e-04\n",
      "Epoch 017 | train_loss 0.9771 | val_acc 0.5671 | val_f1 0.5663 | lr 3.00e-04\n",
      "Epoch 018 | train_loss 0.9646 | val_acc 0.5840 | val_f1 0.5791 | lr 3.00e-04\n",
      "Epoch 019 | train_loss 0.9239 | val_acc 0.5380 | val_f1 0.5329 | lr 3.00e-04\n",
      "Epoch 020 | train_loss 0.8924 | val_acc 0.5897 | val_f1 0.5899 | lr 3.00e-04\n",
      "Epoch 021 | train_loss 0.8647 | val_acc 0.5925 | val_f1 0.5931 | lr 3.00e-04\n",
      "Epoch 022 | train_loss 0.8261 | val_acc 0.6075 | val_f1 0.6058 | lr 3.00e-04\n",
      "Epoch 023 | train_loss 0.7995 | val_acc 0.5775 | val_f1 0.5778 | lr 3.00e-04\n",
      "Epoch 024 | train_loss 0.7573 | val_acc 0.5897 | val_f1 0.5855 | lr 3.00e-04\n",
      "Epoch 025 | train_loss 0.7524 | val_acc 0.6160 | val_f1 0.6177 | lr 3.00e-04\n",
      "Epoch 026 | train_loss 0.7151 | val_acc 0.5784 | val_f1 0.5775 | lr 3.00e-04\n",
      "Epoch 027 | train_loss 0.6632 | val_acc 0.6103 | val_f1 0.6028 | lr 3.00e-04\n",
      "Epoch 028 | train_loss 0.6384 | val_acc 0.5991 | val_f1 0.5898 | lr 1.50e-04\n",
      "Epoch 029 | train_loss 0.5231 | val_acc 0.6235 | val_f1 0.6201 | lr 1.50e-04\n",
      "Epoch 030 | train_loss 0.4676 | val_acc 0.6000 | val_f1 0.6034 | lr 1.50e-04\n",
      "Epoch 031 | train_loss 0.4476 | val_acc 0.6197 | val_f1 0.6220 | lr 1.50e-04\n",
      "Epoch 032 | train_loss 0.4099 | val_acc 0.6113 | val_f1 0.6142 | lr 1.50e-04\n",
      "Epoch 033 | train_loss 0.3796 | val_acc 0.6235 | val_f1 0.6207 | lr 1.50e-04\n",
      "Epoch 034 | train_loss 0.3458 | val_acc 0.6131 | val_f1 0.6137 | lr 7.50e-05\n",
      "Epoch 035 | train_loss 0.2907 | val_acc 0.6178 | val_f1 0.6170 | lr 7.50e-05\n",
      "Epoch 036 | train_loss 0.2575 | val_acc 0.6394 | val_f1 0.6396 | lr 7.50e-05\n",
      "Epoch 037 | train_loss 0.2363 | val_acc 0.6216 | val_f1 0.6257 | lr 7.50e-05\n",
      "Epoch 038 | train_loss 0.2167 | val_acc 0.6244 | val_f1 0.6258 | lr 7.50e-05\n",
      "Epoch 039 | train_loss 0.2071 | val_acc 0.6197 | val_f1 0.6200 | lr 3.75e-05\n",
      "Epoch 040 | train_loss 0.1805 | val_acc 0.6319 | val_f1 0.6312 | lr 3.75e-05\n",
      "Epoch 041 | train_loss 0.1633 | val_acc 0.6291 | val_f1 0.6294 | lr 3.75e-05\n",
      "Epoch 042 | train_loss 0.1458 | val_acc 0.6282 | val_f1 0.6265 | lr 1.87e-05\n",
      "Epoch 043 | train_loss 0.1306 | val_acc 0.6244 | val_f1 0.6247 | lr 1.87e-05\n",
      "Epoch 044 | train_loss 0.1258 | val_acc 0.6310 | val_f1 0.6306 | lr 1.87e-05\n",
      "Early stopping. Best val_f1=0.6396\n",
      "BEST CHECKPOINT | val_acc=0.6394 | val_macro_f1=0.6396\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T02:23:43.023219800Z",
     "start_time": "2026-01-02T02:23:36.810225300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_preds(model, loader, device):\n",
    "    model.eval()\n",
    "    all_y, all_p = [], []\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu().numpy()\n",
    "        all_p.append(preds)\n",
    "        all_y.append(y.numpy())\n",
    "    return np.concatenate(all_y), np.concatenate(all_p)\n",
    "\n",
    "y_true, y_pred = get_preds(model, test_loader, DEVICE)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=[k for k,v in sorted(EMO_MAP.items(), key=lambda x:x[1])]))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ],
   "id": "8f672d35868d0aa7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ANG       0.71      0.75      0.73       208\n",
      "         DIS       0.58      0.59      0.59       208\n",
      "         FEA       0.60      0.52      0.56       207\n",
      "         HAP       0.70      0.50      0.58       208\n",
      "         NEU       0.66      0.73      0.69       178\n",
      "         SAD       0.53      0.67      0.59       208\n",
      "\n",
      "    accuracy                           0.62      1217\n",
      "   macro avg       0.63      0.63      0.62      1217\n",
      "weighted avg       0.63      0.62      0.62      1217\n",
      "\n",
      "[[156  24   5  15   7   1]\n",
      " [ 19 122  10   4  18  35]\n",
      " [ 10  14 107  21   8  47]\n",
      " [ 30  17  36 104  14   7]\n",
      " [  3   6   2   3 130  34]\n",
      " [  2  26  17   2  21 140]]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T02:24:04.498501200Z",
     "start_time": "2026-01-02T02:24:04.466756500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FINAL_PATH = \"cnn_bilstm_emotion.pt\"\n",
    "\n",
    "# model should already be the best one (or load best_path first)\n",
    "torch.save(model.state_dict(), FINAL_PATH)\n",
    "print(\"Saved weights to:\", FINAL_PATH)\n"
   ],
   "id": "cc6db64de6b69faa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights to: cnn_bilstm_emotion.pt\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
